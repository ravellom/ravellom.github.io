una Inteligencia artificial gana un

concurso de pintura una revista

científica Beta autores que usan

Inteligencia artificial para escribir

sus artículos una Inteligencia

artificial puede hacer exámenes muy

difíciles de medicina y abogacía qué

está pasando cómo puede ser que en los

últimos dos años de repente los

ordenadores pueden hacer cosas que hasta

ahora pensábamos que solo nosotros

podíamos hacer y además cosas que

realmente nos hacen plantearnos Qué

significa el arte o si realmente

necesitaremos un abogado en el futuro

para redactar un texto legal o incluso

si harán falta programadores o si las

inteligencias artificiales también están

generando código y sinceramente habiendo

sido programador durante 10 años de mi

vida nunca me imaginé que vería un

ordenador generando de la nada programas

así de elaborados Y la verdad todo esto

hace que uno se sienta bastante perdido

sobre todo los que nos dedicamos a la

informática desde toda la vida o estas

noticias nos hacen dudar nos están

demostrando que cosas que pensábamos que

una máquina no podía hacer ahora resulta

que puede y a veces incluso mejor que

nosotros así así que me propuse

investigar qué hay detrás de estas

inteligencias artificiales y hoy te voy

a contar todo lo que descubrí desde el

punto de vista de un ingeniero de

software explicado para todo el mundo o

sea mi objetivo es que seas quien seas

sin saber nada te puedes hacer ni que

sea una idea de cómo funcionan estas

inteligencias y especialmente Hoy me voy

a centrar en uno de los productos que

están más de moda y que más ruido ha

hecho chat gpt chat gpt es súper popular

todo el mundo la está usando para que os

hagáis una idea consiguió la

escalofriante cifra de 10 millones de

usuarios activos cada día en su primer

mes o sea sale Y a los 30 días ya tenía

10 millones de usuarios cada día

haciendo preguntas rompiendo el récord

de la tecnología más rápidamente

adoptada en la historia de la humanidad

un crecimiento 10 veces más rápido que

el de Instagram una locura total chat

gpt es una web de uso gratuito aunque

también tiene una versión de pago y

funciona como un chat al que le puedes

preguntar todo tipo de cosas es como una

especie de oráculo tecnológico que te

sabe decir cosas Cuál es la mejor manera

de atarte los zapatos Cómo deberías

dejar a tu novia de la forma más suave

resolver problemas lógicos complejos

escribir software hacer cambios en ese

Software que acabas de escribir jugar a

juegos contigo inventar una historia

escribir poemas crearte una rutina de

gimnasio con instrucciones muy

específicas con poner una canción con

sus respectivos acordes generar un texto

legal Como por ejemplo un acuerdo de

confidencialidad y todo esto recordando

todo lo que habéis hablado a lo largo de

la conversación o sea tú hablas con él y

vas recordando todo lo que estás

hablando y son textos originales o sea

todo lo que te dice no lo vas a poder

encontrar en ninguna parte de internet

aunque luego hablaremos de eso cómo es

posible que despertemos una mañana y

esto simplemente exista bueno no ha sido

realmente de la noche a la mañana han

pasado décadas y décadas con muchas

innovaciones tanto en el mundo de la

programación como la informática la

Inteligencia artificial las redes y las

sociedades en Sí esta es lo que se

conoce como una tecnología convergente

vale nace de muchas otras tecnologías

que se juntan llegar al resultado que

vemos hoy en día y esto gente es una

Revolución una Revolución que todavía no

está en su punto pero se viene y para

demostrarte Lo bueno que es le he pedido

a gpt que me genere el sponsor de hoy y

he utilizado una Inteligencia artificial

para que lea el texto Así que vamos a

ver qué tal Bien lo hace con un mensaje

de nuestro sponsor Hola a todos Soy Chad

gpt y Hoy les hablaré sobre la gtc de

nvidia la gtc de nvidia es la

conferencia más grande sobre

Inteligencia artificial aceleración de

gráficos y ciencias de datos este año la

gtc se llevará a cabo en línea el 20 de

este mes y nvidia está organizando un

sorteo especial para los asistentes

podrás ganar una rtx 4.080 si te

registras para asistir a la gtc el

enlace para registrarse está en la

descripción la gtc de envidia incluirá

más de mil sesiones en línea con

presentaciones talleres y discusiones de

expertos podrás escuchar a los

principales expertos de la industria y

aprender sobre los últimos avances en la

informática acelerada la Inteligencia

artificial el aprendizaje automático la

ciencia de datos y mucho más también

tendrás la oportunidad de conectarte con

otros líderes de la industria explorar

nuevas tecnologías y descubrir como las

soluciones de envidia están

transformando la forma en que vivimos y

trabajamos regístrate ahora mismo para

asistir a la gtc de nvidia y tener la

oportunidad de ganar una rtx 4.080 No te

pierdas esta oportunidad única de

aprender sobre los últimos avances en la

informática acelerada y la Inteligencia

artificial el enlace para registrarse

está en la descripción te esperamos en

la gtc de nvidia

[Música]

Ok chat gpt chat gpt está basado en gpt

3 gpt o generative pretend Transformer

es un modelo Esto es algo de lo que ya

hablamos en otros vídeos pero a modo de

resumen un modelo para que te puedas

hacer una idea es un programa un

algoritmo una función que intenta

replicar el comportamiento de un sistema

por ejemplo el más clásico vale el

modelo climático sería un programa un

software o algún tipo de sistema que te

permite predecir el clima de la semana

que viene basándose en datos históricos

no por ejemplo coges el clima de las

últimas semanas el viento las nubes la

humedad coges todo eso lo metes en esta

máquina y la máquina te predice el clima

de la próxima semana otro ejemplo de

esto bueno hace poco en nate Life

hablamos del amp modeling vale que son

modelos que imitan amplificadores de

guitarra imitan toda la parte de

electrónica la parte de amplificación

distorsión reverb incluso la acústica de

una sala y todo esto no ocurre en la

realidad sino que hay un software que

tiene una serie de instrucciones que lo

que hace es simular el resultado que

tendríamos si todo eso y todo esto lo

hace un software un software que es un

modelo gpt como te decía es un modelo

pero un modelo de lenguaje vale el

modelo de lenguaje es capaz de conocer e

identificar partes de nuestro idioma Y

en este caso es un modelo generativo O

sea que dado un texto genera palabras es

como ese modelo que predice el clima

Solo que gpt predice palabras o sea

literalmente te dice Cuál es la palabra

más probable que va a haber a

continuación en un texto si lo piensas

no es muy distinto del autocompletar del

móvil no sé si habrás probado alguna vez

que en el móvil hay un sistema que te

sugiere palabras intentando predecir lo

próximo que vas a decir Solo que gpt es

infinitamente mejor haciendo Ese trabajo

lo hace tan también que parece que

entienda perfectamente de lo que estás

hablando y pueda responder prácticamente

a cualquier cosa de forma coherente Por

ejemplo tú le dices voy a trabajar en mí

y gpt te dice proyecto Y si le pides más

continúa voy a trabajar en mi proyecto

de investigación en el laboratorio estoy

encantado de continuar con mi trabajo y

espero obtener resultados significativos

voy a trabajar duro y concentrarme en

las tareas que tengo por hacer para

avanzar en mi proyecto Wow es un buen

autocompletado verdad Ahora en el caso

de chat gpt que es la página web que

todo el mundo conoce esta página web usa

la tercera versión de gpt gpt 3 como os

dije antes no aunque le llaman también

gpt 3.5 porque tiene unas cuantas

mejoras Pero bueno Eso lo veremos más

adelante vale Y una de las cosas

especiales que tiene chat gpt es que

está especialmente configurada para

completar respuestas como si

estuviéramos en un chat o sea es un

predictor de palabras pero que está

condicionado para tener en cuenta que

nuestro texto es una pregunta o la

intervención de una persona en un chat y

la respuesta que nos genera lo que nos

responde chat gpt es la cadena de

palabras que más probabilidad tienen

según su sistema de aparecer a

continuación o sea predice texto que no

existe pero bueno a nivel técnico la

diferencia principal entre gpt pelado y

chat gpt es que gpt completa textos y

chat gpt pues responde como si

estuvieras hablando con alguien se está

configurado de esa manera luego veremos

que hay muchas más diferencias vale pero

con esto llegaremos ahora todo esto que

estoy diciendo Yo entiendo que es que es

muy raro vale o sea me estás diciendo

que a un modelo que predice palabras le

pregunto Cuál fue el emperador Romano

más malvado de la historia y por qué y

me está soltando que si hay varios

candidatos que calígula es el más

probable me cuenta todo lo que ha hecho

Y encima me dice que es posible que esto

no sea fiable porque podría ser

propaganda que se escribió cuando

calígula ya estaba muerto aquí hay algo

que no cuadra verdad parece que este

autocompletado haya cobrado conciencia

sobre todo lo más impresionante la

primera vez que usas una Inteligencia

artificial de estas Y ves todo este

párrafote tú lo que piensas Es que esto

lo ha copiado de alguna página web y

buscas ese texto incluso trozos el texto

y no lo vas a encontrar porque todo esto

ha sido generado es un texto único

parece que sepa de lo que habla parece

que no se entienda y que nos conteste

algo totalmente relacionado con lo que

estamos diciendo parece capaz de

desarrollar sus propias ideas analizar

datos y sacar conclusiones Pero esto es

totalmente falso no está haciendo nada

de esto en realidad Está prediciendo

palabras y poco más magia aquí es En qué

se basa para predecir esas palabras y

vamos a empezar analizando el problema

juntos para intentar entender la

magnitud del asunto la programación es

la forma más tradicional de hablar con

los ordenadores Pero bueno entiendo que

no todo el mundo sabe programar Así que

no voy a poner un ejemplo de

programación sino que me voy a ir a algo

que todo el mundo haya hecho alguna vez

vale el ejemplo más claro de Cómo hablar

con una máquina es probablemente el de

usar una calculadora si yo quiero sumar

tres números entre ellos con una

calculadora tengo que seguir un orden

muy preciso de acciones si cometo un

error Por ejemplo pongo mal un número

tengo que borrar o Volver a empezar y

esto es muy importante porque la máquina

es estricta es muy estricta a la hora de

recibir los datos de entrada entender

las operaciones que tiene que hacer y

esto es muy distinto a cuando hablamos

con un humano al que por ejemplo le

podríamos decir Oye tío Si tienes un

momento quiero que sumes 3 + 2 Ay no

perdona 4 y luego que lo multipliques

por 8 y nada Cuando puedas me dices el

resultado vale una calculadora no puede

entender esto porque lo estoy diciendo

en lenguaje natural lenguaje que

nosotros por algún motivo somos capaces

de entender muy bien o sea de alguna

forma yo con toda esa frase entiendo que

lo que quieres hacer es 3 + 4 y luego

multiplicado por 8 la calculadora

necesita un input muy concreto expresado

de una forma muy concisa con unas reglas

matemáticas para extraer esa información

mientras que a un humano le puedo dar

vueltas y decir muchas cosas que

generalmente me va a entender Bueno pues

chat gpt resuelve ese problema Mirad si

le digo toda esta frase a Chad gpt

parece que está entendiendo

perfectamente lo que le digo Y además me

calcula la respuesta de forma correcta

como te he dicho hace un momento esto se

llama lenguaje natural el lenguaje

natural es confuso y necesita que lo

analicemos para poder extraer

información los humanos Somos

increíblemente buenos en hacer esto

entendemos los conceptos clave que se

nos quieren transmitir e incluso

planteamos una estrategia para responder

a esa pregunta será chat gpt consciente

de esto

parece que sabe perfectamente de lo que

estoy hablando esto cada vez es más

surrealista verdad cuesta de creer que

lo único que está haciendo esta máquina

es calcular las palabras más probables

que van a aparecer a continuación de mi

texto Pero bueno esto en realidad no son

más que trucos el truco de la red

neuronal veréis gpt que es este modelo

de lenguaje que usa chat gpt como te

dije hace un momento está basado en

redes neuronales hemos explicado por

encima Cómo funcionan las redes

neuronales en mis vídeos sobre el Deep

fake que por cierto si te interesa el

tema de Inteligencia artificial y si

quieres entender Más a fondo este tema

te recomiendo que los veas vale Te los

dejaré linkados abajo en la descripción

y por aquí seguramente vale Pero de

todos modos vamos a repasarlo un poquito

una red neuronal es un programa que está

diseñado para aprender a hacer tareas

normalmente cuando los humanos quieren

hablar con un ordenador y pedirle que

haga cosas usamos la programación vale Y

cuando hacemos un programa le decimos a

la máquina exactamente paso a paso todo

lo que tiene que hacer como hacíamos de

hecho con la calculadora cuando estamos

escribiendo números en una calculadora

en realidad estamos amándola vale Lo que

pasa que es muy sencilla esa

programación Pero hay algunas cosas que

no sabemos muy bien cómo explicarlas

como por ejemplo reconocer un número

escrito a mano vale hay como mil formas

de escribir números a mano o reconocer

un dibujo por muy deformado que esté no

imagínate un dibujo de un gato Cuántas

formas hay de dibujar un gato estas son

tareas que nosotros como humanos sabemos

hacer de forma fácil pero que cuesta

mucho explicarle a un programa Cómo

puede hacer esto paso a paso para todo

esto que no sabemos cómo programar hemos

inventado el aprendizaje automático o

Machine learning y las redes neuronales

son una de las tecnologías que se usan

para el aprendizaje automático la idea

Aquí es muy simple la idea simple la

implementación es difícil vale Pero la

idea es simple quiero que la máquina

haga algo que no sé muy bien cómo se

hace así que le voy a mostrar ejemplos a

mi ordenador voy a preparar mi red

neuronal para que sepa dónde tiene que

mirar qué puntos son los interesantes de

estos datos Qué tipo de operaciones

tiene que hacer con ellos para intentar

sacar conclusiones o sea le voy a dar

una estrategia Pero va a ser ella quien

va a estudiar muchos casos muchísimos

datos muchísimos casos para intentar

entender qué es lo que se tiene que

hacer en cada uno de ellos con estos

datos básicamente mi red neuronal va

sacando conclusiones va encontrando

patrones incluso hay veces que estas

inteligencias artificiales encuentran

detalles que nosotros no somos capaces

de darnos cuenta que están ahí este

proceso en el que la Inteligencia

artificial estudia miles y miles de

casos se llama entrenamiento por ejemplo

podemos entrenar una Inteligencia

artificial para reconocer imágenes de

gatos o números escritos a mano o jugar

a un juego de mesa un ejemplo de esto

que ya vimos en el canal es el del Deep

fake que son estos vídeos que te

mencioné hace nada donde entrenábamos

una Inteligencia artificial para saber

cómo es mi cara y cómo es la cara de Elo

Mask y meter mi cara encima de un vídeo

de elon musk generando caras mías que se

pareciesen a las de elon pero que yo

nunca hubiese puesto vale o sea

literalmente generaba caras de la nada

ahora en el caso del lenguaje natural

que es como te decía antes el que

hablamos nosotros hay varios problemas

bastante graves además a la hora de que

un ordenador nos pueda entender

lo primero es que los ordenadores no van

a entender nunca los conceptos que

representan las palabras por ejemplo si

yo te digo coche tú te imaginas ese

vehículo de cuatro ruedas hecho de metal

ya sentado en un coche sabes cómo vibra

cuando se conduce o si te digo árbol te

imaginas un ser vivo de celulosa el olor

de las hojas color marrón y verde un

ordenador no tiene ni idea de que es

nada de esto es más los ordenadores solo

entienden números ceros y uno para hacer

más concretos esto ya lo vimos Por

cierto en el vídeo de sistema binario y

puertas lógicas que también te

recomiendo que veas para que entiendas

esta parte un poco mejor y bueno en

aquel vídeo vimos que incluso el texto

el audio o el vídeo que estás viendo

para tu ordenador no son nada más que

números con los que hace operaciones

Matemáticas ahora en el caso concreto

del texto una de las codificaciones que

más te va a sonar es el código aci

Aunque hoy en día se usa más el utf8 por

ejemplo Pero bueno que al final del día

las letras que tuviesen tu ordenador en

Word en Wikipedia en cualquiera de estos

sitios en realidad son números que

identifican esos caracteres y el

ordenador los trabaja como números

incluso los espacios los números mismos

los interrogantes hasta los emojis Por

lo cual si quisiéramos entrenar una

Inteligencia artificial para que nos

entienda y hable con nosotros primero

que nada Hay que tener en cuenta que

nuestra red neuronal no va a haber

frases ni palabras ni poemas sino

números y únicamente números y ese

problema no tiene solución vale Así que

vamos a trabajar con números Sí o sí

okay dicho esto tenemos por un lado

redes neuronales que son capaces de

aprender en base a patrones y por otro

lado tenemos texto que este texto en

realidad son pues nuestras frases

palabras un montón de lenguaje humano

pero que para el ordenador al final del

día y es importante este Matiz son

números vale él no va a haber árboles ni

casas ni coches ni caras ni personas

para ver números únicamente Así que

teniendo en cuenta estos dos detalles

vamos a hacer juntos el ejercicio de

crear un programa que entienda el

lenguaje natural vale va a ser un

ejercicio mental Ok vale configuramos

nuestra red neuronal y le pasamos estos

números lo primero que va a ver Son un

montón de números

hemos dicho que una de las habilidades

especiales de nuestra red neuronal es

encontrar patrones dentro de datos Así

que podemos configurarla especialmente

para que reconozca tantos patrones como

pueda y se analiza cientos y cientos de

estas secuencias de números acabaría

dándose cuenta de que hay patrones que

se repiten vale cada vez que encuentra

esta secuencia de números entre estos

dos otros números es porque hay un

término A veces lo encuentra con este

otro número al final pero lo que está

claro es que este es un patrón que se

repite y como ese puede haber muchísimos

otros Esto es lo que nosotros conocemos

como palabras pero para esta red

neuronal para este ordenador son

patrones numéricos únicamente de todos

modos yo creo que aquí el primer paso

sería catalogarlos tenerlos en alguna

lista Cosa que cuando nuestro programa

se los encuentre Pues los pueda

identificar mira aquí veo este patrón

aquí veo este otro etcétera etcétera os

hacéis una idea no a estos patrones les

vamos a llamar toquen un token no es

necesariamente unas palabras depende

mucho de Cómo funciona la red neuronal

pero no es necesariamente una palabra a

hay palabras compuestas o palabras que

varían bastante pero que tienen una raíz

común y el ordenador lo que hace es

separarlas en varios tokens pero bueno

normalmente un token es una palabra y

como nuestra máquina ahora conoce los

tokens una forma de reducir simplificar

y comprimir esos datos y hacer el

trabajo más fácil podría ser la de

cambiar esos patrones de muchos números

por una serie de tokens numéricos vale

vamos a asignar un número a cada token y

vamos a cambiar todas esas secuencias de

números por tokens y ahora la red

neuronal pues tendría un número para

cada palabra en lugar de todo ese lío

este proceso es uno de los primeros

pasos que hacen las redes neuronales

como gpt y se llama tokenización ahora

la máquina conoce las palabras vale pero

no sabe qué significan y nunca lo sabrá

nunca sabrá que esto es una reina ni que

esto es un coche y Aunque no pueda

relacionar estos términos con objetos

del mundo Real Como hacemos nosotros lo

que sí puede hacer si prestan mucha

atención es saber qué términos están

relacionados con Cuáles a alguien se le

ocurrió que podríamos de alguna forma

marcadores en los tokens o sea

todos estos tokens y poner como pequeñas

marquitas cuando detectamos que dos son

similares un poco como jugar al culedo

no donde vas marcando tus pistas de tu

investigación Pues aquí podríamos decir

que la reina suele estar cerca del token

la a igual que la chica o la princesa

por lo que estas palabras tienen un

marcador común también se relacionan con

el token de vestido Por lo cual hay algo

común Ahí lo vamos a marcar también y se

relacionan con el token de comer igual

que los perros y los gatos que por

cierto estos dos también se usan en

patrones similares junto con otros

tokens al igual que caniche o

veterinario o pelota Solo que la pelota

no come vale Y con un texto lo

suficientemente grande por ejemplo

cientos de libros podríamos entrenar un

modelo para crear una gran clasificación

de términos y distintos patrones

similares que va encontrando haciendo

que los tokens sigue sin saber que son

vale Pero de alguna forma están

ordenados y clasificados entre ellos con

estos marcadores para nosotros hacernos

una idea por ejemplo el marcador que

tiene princesa reina y mujer en común

representaría lo femenino vale Aunque

realmente para la máquina esto no tiene

ningún sentido simplemente es un

marcador numérico que dice Pues mira yo

creo que esto está relacionado por el

contexto que he leído de esta forma cada

token tendría un gran número de

marcadores unos 300 Por ejemplo que le

dicen Cuáles son las cosas que tienen

común con otras palabras A ver no es

nada fácil hacerse una imagen mental de

cómo funciona este sistema a mí lo que

me gusta pensar es que cada palabra

tiene como su ADN y tiene rasgos comunes

con otras palabras y de esa forma

podemos saber que están relacionados

Pero hay otra forma que a mucha gente le

funciona para entender mejor este

sistema y es imaginarlo Como una nube

tridimensional de ideas repito en

realidad es bastante más complejo porque

esto en una nube tenemos sólo tres

dimensiones o sea tenemos arriba abajo

derecha izquierda atrás ahí adelante no

tenemos tres dimensiones Pero antes

hemos dicho que un token puede tener 300

marcadores 300 marcadores Serían como

300 dimensiones distintas vale Pero

bueno vamos a imaginarlo de forma

tridimensional como podéis ver en esta

nube tridimensional hay palabras que

están más cerca de otras y podemos hacer

operaciones Matemáticas incluso para

Cuál es la distancia entre ellas Cuáles

son las más cercanas Cuáles son las más

lejanas y por ejemplo dada una palabra o

una posición en el espacio x Podríamos

sacar la lista de palabras o posiciones

más parecidas más cercanas a la que

estamos ahora incluso hacer operaciones

Matemáticas Como por ejemplo reina menos

mujer igual a Rey esto si lo vemos con

el ejemplo del ADN estaríamos quitando a

la reina esas trazas que hacen que se

identifique con lo femenino no le

quitaríamos mujer por lo que tendríamos

una ADN más parecido al del Rey si lo

imaginamos con el mapa espacial

estaríamos alejándonos del término mujer

para irnos al opuesto y en ese sitio en

el opuesto pues estaría Rey no sería un

poco esta la idea este sistema de

codificación se conoce como embedding es

un sistema que permite agrupar palabras

similares e incluso sus tendencias en

cuanto a significado y este mapa tal y

como está sin hacer nada más ya no sirve

para muchas cosas por ejemplo en un

buscador como Google cuando buscas una

palabra podrías también tener en cuenta

pues sinónimos palabras similares o por

ejemplo para saber si es triste o feliz

podrías buscar Dentro de este invading y

ver qué otras palabras hay similares

ahora si nos vamos a ver el sistema de

en beings que usa gpt la cosa es mucho

más compleja como decíamos una palabra

como gato dentro de gpt estaría

representada por un token y dentro de

los envadings estaría representada con

un vector de 300 dimensiones o sea una

lista de 300 coordenadas distintas o 300

marcadores distintos con distintos

niveles pero luego gpt también recuerda

conjuntos de tokens o sea frases por

ejemplo el gato está durmiendo en el

sofá es una secuencia que está hecha de

varios tokens y que también estaría

clasificada dentro de los envadings o

sea estamos hablando de que si bien la

idea original de bedding era

palabras y Buscar Qué relación tienen

entre ellas y crear un sistema complejo

de etiquetado para saber cuáles van por

un lado Cuáles van para otro y cuáles

están relacionadas Y qué tanto están

relacionadas pues gpt lo lleva a otro

nivel porque directamente coge

secuencias de varios tokens o sea frases

enteras y hace lo mismo se acoge frases

y esas frases también las organiza

dentro del espacio con sus respectivas

relaciones y con más de mil marcadores

para cada frase o sea como puedes

imaginar es un sistema bastante grande y

aquí hay un Matiz muy importante vale

esto es muy clave y es el motivo por el

que Chad gpt parece que invente cosas en

lugar de copiar textos de otras personas

aquí es donde está toda la chicha vamos

a volver a nuestra máquina nuestro

algoritmo hasta aquí habíamos dicho que

vamos a crear este sistema de en

beadings que es una técnica muy común

que se usa para relacionar un poco el

significado entre palabras y bueno ahora

haciendo nuestra clasificación nos damos

cuenta de que hay palabras como él la

como mismo otros Ojalá y términos

similares que aportan muy poco valor a

la frase o sea es como que están en

tierra de nadie se relacionan con todo y

con nada al mismo tiempo al igual que

las mayúsculas las minúsculas y otros

signos de puntuación que a veces pues

aportan muy poco a una frase no la frase

se entendería igual si esos términos

genéricos no estuvieran ahí así que de

ahora en adelante para simplificar

todavía más el trabajo que todo vaya más

rápido y que más simple también

relacionar frases pues vamos a limpiar

los textos antes de meterlos a nuestro

sistema esto para que te hagas una idea

es como cuando te limpian el pescado

vale te quitan las espinas las escamas

te lo dejan listo para cocinar y que

cuando te lo comas te lo comas enterito

esto sería algo muy parecido te voy a

poner un ejemplo en la frase el gato

está durmiendo en el sofá hay varias

palabras que aportan poco por ejemplo en

y él si las quitamos nos queda gato está

durmiendo sofá esto también se entiende

podríamos simplificarla aún más con un

proceso que se llama lematización o sea

Convertir las palabras a sus formas más

sencillas Como por ejemplo los verbos al

infinitivo gato es dormir sofá y si lo

simplificamos aún más gato dormir sofá

es una frase que está comprimida está

condensada Y esto es muy útil cuando

entrenamos el modelo porque Qué pasa que

gpt guardaría esta secuencia dentro del

sistema de ending relacionando esta

frase con otras frases parecidas usando

los marcadores pero en lugar de

una frase que es súper larga con un

montón de palabras pues la reduce a la

mínima expresión y aquí viene la gran

revelación todas las frases que dice gpt

la saca de su sistema de medings vale

todo lo que gpt dice sale de una

búsqueda dentro de los envadings Busca

términos palabras o incluso frases y

consigue otras frases que son parecidas

y están relacionadas de alguna forma no

con esta Este es el gran truco del

conocimiento y la gran capacidad de chat

gpt para poder decir cosas relacionadas

con lo que nosotros estamos diciendo o

sea literalmente coge nuestras frases

las analiza las convierte a su sistema

de ening y busca en ese espacio de

meding qué más nos puede decir antes le

pregunté por los emperadores romanos no

por ejemplo y todo lo que me dijo pues

es una mezcla de varias secuencias de

tokens que están almacenados y

relacionados entre ellos dentro de su

sistema de medings Pero esto es solo el

principio vale antes hablé de

normalización y lematización que es este

proceso en el que limpias el pescado

simplificas las frases Por decirlo de

alguna manera quitas todo eso que no

aporta y comprimes la información usando

tokens para representar una frase y esto

para entender Por qué chat gpt genera

textos únicos me explico cuando charge

gpt genera texto hace consultas a su

envading y lo que saca son estas

secuencias de tokens que son frases

comprimidas y que las tiene que

convertir en algo aceptable por parte de

los humanos por eso lo que hace es

convertir estos tokens en las palabras

que están más cercanas en la dentro del

envading a veces las palabras son

ligeramente distintas a las que estaban

en la frase original y sobre todo usa

nuestras reglas de sintaxis y gramática

Para volver a poner esas palabras que

había quitado al principio convirtiendo

esa secuencia de números en una frase

que le suene bien a un ser humano Pero

qué pasa que de la frase original a la

final ha habido una pérdida de

información y luego una reconstrucción

por eso la frase es distinta la original

porque es imposible recordar exactamente

qué es lo que había en la frase original

Así que se lo inventa y pone cosas que a

veces son distintas Y esto es bueno es

muy bueno porque lo que hace es que lo

que genera chat gpt no se parezca al

texto original o sea es una creación

original porque literalmente cuando ha

guardado esa información ha perdido

detalles y los ha tenido que reconstruir

y los ha reconstruido pues ha cambiado

cosas es muy parecido a lo que hacemos

nosotros y lo pensáis si yo ahora te

explico algo Y mañana te pregunto qué es

lo que te he explicado Pues tú

seguramente tengas una serie de ideas

que recuerdes de lo que te expliqué pero

no me vas a recitar exactamente las

palabras que te dije porque no te vas a

acordar sino que me vas a decir pues con

tus propias palabras lo que te dije ayer

pues es muy parecido a lo que hace gpt

reduce y comprime el significado básico

almacena y cuando lo tiene que sacar lo

reconstruye con sus propias palabras por

decirlo de alguna manera aparte de esto

gpt usa otra técnica que se llama

sampling el sampling básicamente permite

que chat gpt tenga una cierta

creatividad lo que hace básicamente es

que el sistema genere un número

aleatorio que sería el equivalente Pues

a tirar un dado vale para que te hagas

una idea de lo que es un número

aleatorio y en base a ese número

aleatorio se mueve ligeramente dentro

del espacio del envending para un lado

para otro y eso le hace pues moverse

hacia otra frase Y esa frase no va a

estar demasiado lejos de la original lo

suficientemente cerca como para que haga

parte de la misma conversación y sea

coherente con lo que estamos hablando

Así es como chat gpt inventando

historias que parecen coherentes pero

que en realidad son combinaciones de

otras historias que ha leído antes en su

fase de entrenamiento o sea todo lo que

dice y todo lo que suelta viene de la

fase de entrenamiento

Ok Hemos llegado a un checkpoint Vamos a

repasar un momento lo que hemos hablado

hasta aquí tenemos una red neuronal que

es un ordenador que aprende buscando

patrones en datos le pasamos un montón

de números Random que representan las

letras de nuestros textos y millones de

textos para que pueda estudiarlos y

Buscar patrones dentro de ellos de ahí

la red saca varios patrones que son

nuestras palabras o partes de palabras y

crea los tokens ahora teniendo estos

tokens los usa para crearse un mapa

mental con cientos de parámetros y usa

esos parámetros para clasificar por

cercanía de significado a cada uno de

los términos y luego gracias a esto Pues

también analiza combinaciones de varios

tokens que parece que tienen algún

sentido entre ellos que son nuestras

frases y también empieza a memorizarlas

y a relacionarlas entre ellas con más de

mil parámetros y esto le permite Pues

saber qué frases tienen cosas en común y

qué cosas en no con qué términos se

relacionan ahora Gracias a todo esto

cuando nosotros le damos un término Como

por ejemplo gato gpt puede buscar dentro

de su envading la posición del término

gato y soltarnos unas cuantas frases

sobre los datos como por ejemplo que es

un gato Cuántos gatos hay en el mundo

Pero además como estas frases están

guardadas dentro del bedding de gpt de

forma súper primaria las tiene que

reconstruir para que suenen como si las

hubiese escrito un humano y haciendo ese

proceso de reconstrucción genera frases

Originales por lo que parece que sepa un

montón de cosas Y gracias al sampling

también bailando y soltando frases

nuevas que quedan bien con las

anteriores un buen truco verdad

pero nos estamos dejando una parte muy

importante el gran problema que ha

existido durante mucho tiempo y para el

que hasta hace muy poco no había

solución

Ok primero que nada recordado una cosa

las redes neuronales tienen dos fases

una fase en la que la entrenamos para

hacer algo y otra fase en la que la hace

no la primera fase se llama

entrenamiento la segunda se llama

inferencia cuando nosotros hablamos con

chat gpt estamos en fase de inferencia

vale está intentando adivinar cosas y

cuando la entrenamos que cuando le

pasamos la Wikipedia los libros y todo

lo que le demos para aprender es cuando

está aprendiendo y el problema que te

voy a contar ahora afecta a las dos

fases tanto la de entrenamiento como la

diferencia cuando nosotros metemos

letras y luego tokens en la red neuronal

vale como lo que el ordenador que

veníamos haciendo hasta ahora la red

neuronal tiene una entrada de un tamaño

x vale recoge esa entrada la procesa

saca conclusiones y ya está y hemos

terminado nosotros hasta aquí por algún

motivo hemos dado por hecho que el

ordenador puede tragar cualquier tipo de

frase cualquier tamaño da igual como sea

cualquier texto Pero esto no es así vale

Y esto es un problema mucho más grande

de lo que parece la red neuronal no

Recuerda lo que pasa entre paso y paso

cada vez y Sale pues simplemente se le

olvida Y esto es un gran problema

primero que nada para la inferencia no

cuando nosotros hablamos con la

inteligencia Y Esperamos que nos genere

texto hombre pues es bastante importante

que entienda toda la frase que le

pasamos da igual cuántas cosas

mencionemos que esto es algo que gpt

hace muy bien y no sólo eso sino que

recuerde todo lo que vamos hablando a lo

largo de la conversación que tenga algún

tipo de memoria no algo que le permita

recordar y lo mismo pasa cuando esta red

está aprendiendo no si la red neuronal

está leyendo un artículo de Wikipedia es

súper importante que para poder

clasificar las frases y conceptos pues

sepa Cuál es el contexto no que es lo

que está leyendo de qué va la cosa por

ejemplo antes hablando con ella pues me

dijo Hay una posibilidad de que estos

textos sean propaganda esto lo hizo una

fase de inferencia porque estaba

hablando conmigo vale eso significa que

durante el entrenamiento en algún

momento leído esa frase y sabía de qué

se hablaba no sabía que se hablaba de

los textos antiguos sobre el emperador

Romano calígula y sabía de todo esto

porque yo le pregunté quién era el peor

emperador Romano de la historia no te

puedes imaginar sin todo este contexto

sería prácticamente imposible hilar una

conversación con sentido esto Ahora nos

parece Obvio porque vemos que funciona y

ya está pero no es tan fácil No es tan

fácil de conseguir porque como te decía

antes la red neuronal tiene un tamaño de

entrada que es limitado Así que necesito

algún tipo de sistema para poder tener

en cuenta el contexto saber de qué

estamos hablando recordar esos detalles

que hacen que la conversación y la frase

tenga algún tipo de sentido hasta hace

poco lo que se hacía era usar redes

neuronales recurrentes Bueno pues en la

red neuronal recurrente lo que se hace

Es que a cada vez que se procesa un

token se guarda una parte del resultado

y ese resultado lo usa como dato de

entrada para procesar el siguiente token

y el siguiente y el siguiente y el

siguiente y cada vez que pasa por un

paso va guardando un poquito de

significado de cada token conseguimos

más o menos que se mantenga el tema del

que estamos hablando a lo largo de una

frase Pero hay dos problemas muy grandes

con este sistema el primero es que

después de X palabras empieza a olvidar

de todo vale o sea llega un momento que

ya el significado de las primeras

palabras se pierde y ya no es capaz de

retenerlo hay un segundo problema muy

importante y es que todo esto es un

proceso secuencial o sea cuando

entrenamos el modelo de lenguaje lo

hacemos en secuencia un término detrás

de otro vamos poco a poco y esto lo que

no se puede es paralelizar Qué quiere

decir esto que si yo por ejemplo quiero

meter más ordenadores a procesar este

texto pues literalmente no podría porque

para procesar una palabra necesito tener

en cuenta todas las anteriores entonces

solo un ordenador puede hacer ese

trabajo o sea imagínate que yo soy la

red neuronal invito a un amigo a que

venga aquí a echar una mano a procesar

todo esto y yo pues estoy ahí procesando

palabra palabra palabra palabra palabra

palabra palabra pero para cada palabra

que proceso tengo en cuenta todas las

anteriores eso significa que mi amigo no

puede hacer nada o sea nos podemos ir

turnando si él quiere pero es que él no

puede ir procesando otras porque le

faltan todas las anteriores Y por eso es

un problema vale o sea entrenar este

tipo de redes es bastante lento Pero

bueno Esto funcionó durante bastante

tiempo era la forma que teníamos para

hacer este tipo de Bots Aunque luego

vinieron otro tipo de redes que son las

long short Memory que son un poco

mejores porque hacen prácticamente lo

mismo pero deciden en cada que es lo más

importante y sólo olvidan lo menos

importante pero bueno siguen teniendo el

mismo problema O sea que a medida que

nos alejamos del texto antiguo se pierde

el contexto queda lo más importante pero

aún así en textos de más de mil palabras

se empieza a perder el significado y

además eso que el entrenamiento no es

paralelizable así que el gran problema

de este tipo de inteligencias

artificiales hasta ahora era que no

podían recordar bien de lo que estaban

hablando o sea igual tenía este en tenía

de todo esto tan Guay Pero dentro de una

conversación muy larga se iban perdiendo

y empezaron a divagar y esto también les

impide desarrollar cosas muy largas

hacer resúmenes o cualquier tipo de

tarea que requiera analizar un texto muy

grande y entender cosas complejas no la

solución a este problema vino en 2017

cuando se publicó attention is all

United que es un paper de unos

investigadores de Google donde se

plantea una solución muy buena este

problema una nueva forma de organizar

las redes neuronales llamada

Transformers en los Transformers lo que

se hace es Añadir una nueva capa una

capa dedicada a lo que de los

investigadores llamaron atención la

atención hace referencia a cómo los

humanos vemos vale nosotros cuando vemos

cosas vemos un montón de información

pero solo prestamos atención a ciertos

objetos mientras que todo el resto pues

lo ignoramos la idea aquí es que nuestra

red neuronal haga Exactamente lo mismo

que analice una gran cantidad de texto

todo de golpe y lo use para extraer el

contexto de lo que se está hablando

prestando atención solo a los detalles

más importantes para hacer esto cogemos

una parte de nuestro texto la

normalizamos la codificamos con nuestros

tokens y de esos tokens vamos a sacar de

cada uno los vectores de embedink a

partir de Aquí vamos a cada uno de

los vectores y vamos a mirar qué tanto

se parecen a todo el resto de palabras

que hay dentro de la frase por ejemplo

en la frase La vida es bella así que

vive la cada día aquí haríamos

operaciones para saber cuál es la

relación con cada uno de los términos Y

de esa forma sabríamos qué conceptos son

más importantes que otros sabríamos Cuál

es el contexto de la frase sabríamos que

cuando hablamos de vivir nos referimos a

la vida y descartaríamos esas palabras

que son menos importantes y aquí la idea

es que la información sobre estos

términos relevantes no solo se va

enriqueciendo sino que también se va

manteniendo a lo largo de todo el

proceso y ese vector de atención se usa

en el procesamiento de cada una de las

palabras y esto ayuda muchísimo al

ordenador no solo a saber el contexto de

cada una de las frases por ejemplo

cuando lee el token propaganda sabe que

se hace referencia a las escrituras

sobre calígula el emperador Romano sino

que además sabe el significado de

palabras Como por ejemplo gato no gato

para un mecánico Es una herramienta pero

Generalmente pues es un animal que para

una persona normal puede ser una mascota

para un veterinario un paciente la

atención también es la que permite a

chat gpt extraer los conceptos clave de

un texto escrito por nosotros saber qué

términos tienen más peso que es lo más

importante de nuestra pregunta incluso

hacer un resumen de un texto o responder

tema por tema a todo lo que le hemos

dicho Pero además hay un poder muy

grande en la capa de atención Esto es lo

mejor que tiene vale Y es que permite

paralelizar me explico la atención no

necesita que las palabras se procesen de

forma secuencial O sea no hace falta

palabra por palabra una detrás de la

otra sino que podemos todas las

palabras al mismo tiempo y esto nos

permite tener decenas de tarjetas

gráficas trabajando todas a la vez

entrenando nuestro modelo de lenguaje o

incluso generando palabras en nuestro

modelo de lenguaje Así que el

entrenamiento es mucho más rápido y

mucho más eficaz que los tipos que vimos

antes no que necesitabas ir de forma

secuencial una tras otra una tras otra

una tras otra aquí coges todo junto se

lo metes Y es capaz de procesarlo a la

vez la idea aquí es que los Transformers

han sido la gran Revolución la pieza que

faltaba en el mundo de los generadores

de texto la capa de atención esa capa de

atención ha hecho que avancemos en dos o

tres años muchísimo más de lo que se

avanzó en toda la década pasada

posiblemente Google de hecho fue la

primera en publicar acerca de estos

Transformers y también en usarlos uno de

los productos más importantes que

hicieron basándose en esta tecnología

fue bert en este artículo de Google

podéis ver como bert es una gran ayuda a

la hora de mejorar la precisión de las

búsquedas en Google por ejemplo no la

mejora es impresionante porque pasamos

de que Google busque términos

relacionados con lo que estamos buscando

a que entienda perfectamente lo que está

diciendo y te dé la solución a tu

problema Por ejemplo aquí podéis ver que

se pregunta si en 2019 un viajero

brasileño necesita visa para ir a los

Estados Unidos antes de usar este

sistema te decía que bueno un artículo

ahí del Washington post que está

relacionado que tiene esas palabras

clave y ahora directamente te lleva a la

página de la embajada donde nos explica

los requisitos de Los viajeros que

visitan Estados Unidos con nacionalidad

brasileña o sea mucho más efectivo más

el grano y te lleva exactamente la

página que Necesitas visitar para para

resolver este problema no Google inventó

este sistema Pero Open los que

decidieron llevar esto al siguiente

nivel en 2015 Se juntaron varios Titanes

del sector tecnológico estamos hablando

de Sam altman que era el director de una

aceleradora de startup muy importante

crack brockman que fue uno de los

primeros empleados de stripe rade

Hoffman que es el cofundador de linkedin

Jessica Livingston que también viene de

la aceleradora de startup será la

cofundadora Peter fiel que es el

cofundador de PayPal y elon musk que

bueno este no necesita presentaciones

Bueno pues toda esta gente se juntó Y

montó una organización que al principio

era sin ánimo de lucro para llevar la

Inteligencia artificial al siguiente

nivel y así es como nació opening uno de

los proyectos estrella de openiz es gpt

no es el único vale tienen cosas muy

guapas Pero bueno gpt es el del que va

el vídeo de hoy y la idea Aquí es muy

sencilla dijeron Qué pasaría si

cogiéramos esta arquitectura de

Transformers que propuso Google y

hacemos la red neuronal más grande

enorme gigantesca jamás creada cada red

neuronal tiene lo que se conocen como

parámetros puedes imaginar los

parámetros como si fueran una serie de

mandos tiradores perillas pesos y una

serie de ajustes que se configuran para

que la máquina funcione de una forma

concreta las redes neuronales de hecho

lo que van haciendo a medida que

aprenden es poco a poco ajustar todos

estos parámetros para que los resultados

de salida sean los esperados de la

máquina vale Y como podrás imaginar

Cuantos más parámetros tiene una máquina

en teoría más ajustable es más compleja

y más flexibilidad tiene y para que

quede claro no en el caso de las redes

neuronales no es el usuario que en

ajusta todo esto no sino que es la

máquina que cambiando todo esto para

producir un resultado x no es como una

máquina que es capaz de aprender Y el

aprendizaje consiste en ajustar estos

parámetros ahora dicho esto este tipo de

grandes modelos de lenguaje Normalmente

se entrenan con algunos millones de

parámetros pero como te dije hace un

momento opening quería llevar esto al

siguiente nivel así que ya cuando

entrenaron a gpt 2 usaron 1,5 miles de

millones de parámetros y ya para gp3 que

es en la que se basa chat gpt usaron 175

miles de millones de parámetros una

locura total y que usaron para entrenar

a esta bestia de Transformers con esos

175 miles de millones de parámetros

bueno Pues básicamente le pasaron el

common Crown que es una base de datos

que contiene muchísimo contenido de

internet extraído de textos como blogs y

todo tipo de páginas web entre el año

2016 y 2019 luego también usaron webtext

2 que básicamente es un texto muy largo

que contiene todos los posts de reddit

con un mínimo de karma y todo Su

contenido de links o sea todos los links

de esos posts también en formato de

texto aparte de eso usar una gran

biblioteca de libros Y por último toda

la Wikipedia y en fin todos estos textos

que son miles y miles y miles y miles de

tokens los usaron para que gp3 aprenda

todo lo que sabe y claro entre este

contenido hay cientos de Consejos

conocimiento general tablaturas de

guitarra código de programación de todo

tipo y muchas más cosas esto es gp3

señores y chats no es el primer producto

basado en gp3 opening creó a mitad de

2021 una variante de gp3 entrenada con

todos los repositorios de github que

básicamente github es una plataforma que

ahora la compró Microsoft donde la

mayoría de programadores del mundo

guardan su código y esta Inteligencia

artificial Pues básicamente se puso

aprender todo el código de github y ha

aprendido a programar esto lo cogieron y

lo sacaron como un producto comercial

llamado github copilot que es una

Inteligencia artificial capaz de

ayudarte a programar generando código de

todo lo que tú le pides directamente

desde tu editor O sea tú estás en el

editor y le dices quiero que hagas esto

genera y todo el código A veces tienes

que cambiar alguna cosa ajustar puedas

modificar Pero toda una Revolución en el

mundo de la programación ahora chat gpt

es lo último que han sacado y para crear

chat gpt han tenido que hacer un poco

más de trabajo vale chat gpt es una

versión refinada o find Toons como se

dice en inglés de gp3 lo primero que

hicieron fue empezando ya desde gp3

entrenado con todo esto que os dije

antes añadieron más entrenamiento pero

esta vez en lugar de usar textos de

internet que quedan libres a la

interpretación de gpt porque una cosa

que no menciona es que gpt es un modelo

entrenado de forma No supervisada o sea

los datos que se le pasaron no le

decimos que son sino que tiene que

buscarse la vida vale pero en este caso

sí que le pasaron un nuevo set de datos

que sí que está etiquetado como lo

hicieron Bueno pues contrataron un grupo

de humanos para que generen respuestas

de chat de alta calidad y además pues

diciendo que es cada cosa Esto se conoce

como aprendizaje supervisado porque la

Inteligencia artificial ya sabe Cuáles

son las conclusiones que tiene que sacar

o sea tiene que buscar los patrones el

Por qué esas conclusiones son así pero

por lo menos ya le decimos Mira esto es

esto Esto es esto Esto es esto Entonces

cuando se centra más en entender de Por

qué las cosas son como son este set de

datos especialmente hecho para gpt es

bastante caro porque tienes que pagar a

la gente para que se dedique a escribir

y etiquetar pero es muy valioso Porque

le da datos de altísima calidad al

modelo Pero además de eso hicieron un

segundo paso un proceso que se llama

rainforcement learning from human

feedback en español aprendizaje

reforzado de feedback humano aquí lo que

hicieron fue hacer que gpt genere cuatro

posibles respuestas para cada pregunta

no y luego pusieron a un montón de gente

ahí a trabajar donde tenían que puntuar

de mejor a peor cada una de las

respuestas de esta forma el modelo va

aprendiendo Cuáles respuestas y cuáles

caminos son mejores o por lo menos más

satisfactorios para el ser humano en

base a todo este trabajo crearon una

página web donde la respuesta está

generada por este gpt mejorado y

ultratuneado y así es como nace Chad gpt

por todo esto chat gpt es tan bueno

haciendo lo que hace en pocas palabras

una startup de Inteligencia artificial

cogió los Transformers y pensó Oye qué

pasaría si multiplicamos por mil los

parámetros respecto está haciendo todo

el mundo y luego lo entrenamos con todo

el texto de conocimiento humano que

podamos tener entre manos y luego lo

tuneamos aún más para terminar de

corregir esas cosas que hace mal y luego

Además le enseñamos qué respuestas son

buenas y cuáles son malas luego lo

metemos en una web y lo vendemos qué

pasaría Bueno pues lo que pasa es Chad

gpt Y cuánto más se puede mejorar gpt si

le metemos por ejemplo mil millones de

parámetros O 100 billones de parámetros

Bueno pues eso no está claro o sea la

tecnología de base son los Transformers

esta tecnología es buena se puede

mejorar bastante con ajustes manuales

guiados por el Humano pero posiblemente

para que podamos competir con el ser

humano no va a ser suficiente

simplemente aumentar estos parámetros

vamos a tener que mejorar la forma en la

que aprendemos y analizamos los textos

ya sea con más capas o con otro

algoritmo o con otra arquitectura pero

el ritmo que va esto es cuestión de

pocos años antes de que descubramos algo

mejor o quizás no a lo mejor podríamos

estar delante de un estancamiento no

todo esto lo dirá el tiempo Pero bueno

ya veis que con ajustes manuales se

puede conseguir que gpt haga maravillas

lo que sí te puedo decir es que entrenar

a una Inteligencia artificial usando 75

miles de millones de parámetros no es

algo que puedas hacer en tu casa en una

tarde simplemente con una tarjeta

gráfica da igual la Gráfica que tengas

da igual que tengas un ordenador con

tres rtx 4090 o sea aún así no podrías

hacerlo para entrenar a gpt con tantos

datos y tantísimos parámetros necesitas

muchísimos ordenadores y mucha Potencia

de hecho gpt fue entrenado sobre las

gráficas a 100 de envidia que son la

gama más alta y más potente que están

pensadas para cálculos de Inteligencia

artificial pero no en una ni dos sino

que en datacenters gigantes de Microsoft

Así es Microsoft ha puesto su Cloud

azure a disposición de openite para

hacer todo este entrenamiento es más

Microsoft Lleva años apostando por

opening y hace muy poco ha invertido 10

miles de millones de dólares en chat gpt

recuerdas que hace un momento te hablé

de github copilot y de cómo gpt entrenó

con github para aprender sobre

programación Bueno pues github es de

Microsoft es más ahora mismo Microsoft

es propietaria del 49% de openi Y no

sólo eso sino que hace unas semanas

anunciaron algo que nos dejó a todos con

la boca abierta su buscador Bing Sí ese

que es competencia de Google que la

gente usa para buscar Google Chrome y

descargárselo Bueno pues ahora Bing

tiene una pestaña que se llama chat esta

pestaña está en beta y lo que tiene es

una versión modificada de chat gpt que

ahora mismo puede buscar en Bing para

responder a temas de actualidad claro

tener en cuenta una cosa como os dije

antes chat gpt está entrenado en base a

datos de internet libros y un montón de

cosas pero su conocimiento se para en

2019 O sea a partir de 2019 no sabe nada

porque el set de datos que se usó para

entrenarlo es ese lo que ha hecho Bing

es muy distinto lo que ha hecho bien es

usar chats tal como viene pero meter la

información extra en tiempo real de

búsquedas que hacen internet o sea va

buscando cosas en Bing páginas web

relacionadas con lo que tú estás

diciendo se las mete para que chat gpt

las lea las procese y las resumas y

luego las integre dentro de su respuesta

por lo cual Bing chat que sería pues

este chat gpt con acceso a internet

puede contestar a cosas de actualidad y

lo que puede hacer la verdad es muy

impresionante esto ha dejado bastante

mal a Google que por cierto es la

empresa más importante del mundo de

Inteligencia artificial de hecho como te

dije antes casi todas las tecnologías

que están detrás de gpt fueron

desarrolladas por investigadores de

Google y esto nos lleva a otra pregunta

que probablemente te estés haciendo

ahora mismo porque Google o Apple o

cualquiera de estas empresas grandes

tecnológicas no ha sacado algo como gpt

antes Bueno Google y otras empresas

tienen grandes modelos de lenguaje como

gpt lo que no tienen es un servicio Como

chat gpt vale Y la respuesta de Google a

Por qué no tienen eso y que además tiene

todo el sentido del mundo es que no se

pueden permitir el lujo de sacar algo

así O sea pensad que estas inteligencias

artificiales aprenden por su cuenta y es

bastante difícil controlarlo no gpt por

ejemplo fue entrenada con millones de

datos y evidentemente dentro de esos

datos no se ha revisado todo no se ha

revisado uno por uno todos los textos

mensajes etcétera eso significa que

fácilmente puede dar respuestas racistas

que te ayuden a cometer crímenes que

propongan cosas inmorales o

absolutamente ilegales esto en chat gpt

ha pasado desde el principio de hecho y

ahora se está controlando mucho o sea

día a día van Ajustando van bloqueando

cosas frases respuestas lo van cortando

por todos lados pero al principio era

bastante heavy y aún hoy en día salen

noticias sobre cosas raras que contesta

Chad gpt y también sobre todo Bing está

bastante salvaje Open ella y por otra

parte es una startup ese problema no es

tan dramático o polémico como Sería para

Google al final es una startup de

Inteligencia artificial y está para eso

para innovar y para hacer una tortilla

pues hay que romper algunos huevos no

tienen realmente tantas políticas

internas ni tanta imagen que cuidar ni

tanta burocracia a la hora de lanzar un

producto y por eso pues muchas veces

vemos Que empresas muy pequeñas hacen

cosas que otras empresas mucho más

grandes y que tienen todos los recursos

para hacerlas pues no las hacen Pero lo

que sí está claro es que en Microsoft se

está poniendo mucho las pilas y que

estos últimos años ha mejorado mucho su

Cloud ha comprado muchas empresas y ha

puesto mucho esfuerzo en la Inteligencia

artificial esta Apuesta por Open es una

Clara señal de que van a por Google y

todo de empresas Apple Microsoft Google

tesla están invirtiendo millones en este

tipo de tecnologías de Inteligencia

artificial porque saben que el futuro va

por ahí todo esto suena muy bien pero

todavía no estamos en ese punto gpt chat

gpt Bing chat y todas sus variantes aún

están un poco lejos de poder sustituir

un buscador por qué bueno Piénsalo de

esta manera hemos dicho que gpt funciona

con conceptos relacionados y cosas que

le suenan internamente que pueden estar

relacionadas las unas con las otras

bueno Pues resulta que por culpa de esto

la información que nos da chat gbd no

siempre es verdad es cierto que todos

los mensajes que nos escribe chats son

pero símiles o sea se parecen algo que

es verdad pero no siempre son verdad son

agrupaciones de cosas que cree que

tienen sentido que vayan juntas un

ejemplo es cuando le pedí que me resuma

un guión sobre la guerra de los chips en

el que llevamos meses trabajando en el

que mencionamos por encima en una frase

creo que es la crisis de los coches no

de que por culpa de que no hay chips

pues la industria de los coches está

perjudicada y cuando me dio el se

inventó un montón de cosas por ejemplo

me contó 40 mil cosas sobre los coches o

sea nada que ver con nada de lo que

decía en el vídeo o por ejemplo le pedí

que me escriba un guión sobre las Team

deck y empezó ahí a cruzar datos a decir

cosas que no son ciertas y lo hace De

esta manera porque al final lo que está

haciendo son consultas dentro del

embelín o sea está mezclando conceptos

hay cosas que él cree que están

relacionadas pero que no sabe

exactamente si están bien relacionadas

no es infalible y es una gran fuente de

desinformación a veces Incluso te dice

lo que quieres oír es más te acuerdas

que antes Te dije que Google puso la

excusa de que no podía permitirse el

lujo de sacar una Inteligencia

artificial como lo hizo opening bueno

Pues resulta que hace nada presentar una

Bart que es la competencia de Google a

chat gpt y en su primer vídeo

promocional ya cometí un error dijo que

el telescopio James webb hizo fotos de

exoplanetas cosa que es mentira esto

hizo caer en bolsa Google un 8% que

básicamente son 100 mil millones de

dólares por lo cual como podéis ver pues

es bastante grave un error de ese tipo

Ahora yo lo que creo Es que este tipo de

problemas no tan fáciles de arreglar o

sea tal y como funcionan los

Transformers si piensas en todo lo que

hemos visto Este vídeo Es normal que la

información no sea exacta porque el

sistema no es exacto no es una forma

super eficiente de guardar información

consultarla y recibirla sino que es eso

texto que parece verdad básicamente lo

que necesitamos ahora mismo Son un

montón de parches humanos que corrigen

cosas que cierran cosas que le impiden

hacer cosas tirar por ciertos caminos y

esto no es escalable y no es por ser

agua fiestas Pero puede ser que pasen

varios años antes de que se pueda

solucionar este problema en cualquier

caso lo que está claro es que estamos

delante de una guerra una guerra entre

tecnológicas una guerra que va a ganar

la primera que sea capaz de dominar el

juego de las inteligencias artificiales

sobre todo los buscadores semánticos y

el uso de internet ese día va a llegar

Qué tan lejos estamos Bueno pues el

tiempo nos lo dirá de momento yo te

animo a que pruebes adjepete vale

regístrate úsalo para tu trabajo úsalo

para lo que quieras pero no te fíes de

la información porque podría estar mal y

con esto Me despido espero que te haya

gustado este vídeo que hayas entendido

un poco de qué va este tema de dónde

sale esa información cómo puede existir

este tipo de Inteligencia artificial que

parece brujería y si te ha gustado este

vídeo y quieres ver más como este te

recomiendo que te suscribas a este canal

me dejes una manito para arriba y nos

vemos en el próximo

[Música]

